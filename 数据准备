训练集 VS 开发集 VS 测试集   60/20/20 or 70/30  （当数据较大时可相应减少比例，e.g:100w-> 98w 1w 1w）
开发集：可用于检测是否高方差，选择合适的模型
（每个集的数据应有相同的分布）
（例外： e.g:如果预测不清晰的图片，数量很少1W，但拥有99W清晰的图片，此时应把清晰图片全部放入训练集）



高偏差：模型效果很差（更换模型 or 调整超参数）
高方差：开发集效果比训练集差很多（考虑过拟合，增加数据，正则化）


正则化：
L1正则化：L+1/m*sum(||W||)
L2正则化：L+1/2m*sum(||W||2)  (常用)(m数据的个数）
Dropout(随机失活）正则化：每次迭代时以一定概率让一些神经元失活。（可避免模型过于依赖某一个特征，使每一个权重都比较小）
数据集扩增（对于图片可以通过旋转，裁剪等措施增加数据）
早终止（训练次数减少）


数据归一化：
最值归一化：xscale=(x-xmin)/(xmax-xmin)
均值方差归一化（z-score标准化）：xscale=(x-u)/标准差
（测试集和训练集应进行同样的操作。可归一化后再分）


梯度消失与爆炸：
权重初始化
小型网络可随机初始化为较小的数
Xavier：
